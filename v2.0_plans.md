General:
--------
* Performance info collection code is the same as in wally.
  Need to unify this.
* Upload result to git repo --git-url/--git-branch/--git-dir
copy + git add + git commit -m "datetime - cluster status/osd count/data size" + git push

  
Performance info collection:
----------------------------
* virtual domains IO info via virsh
* virsh domblklist - get devs source
* virsh domblkstat XXX
* virsh domifstat XXX
    http://libvirt.org/docs/libvirt-appdev-guide-python/en-US/html/libvirt_application_development_guide_using_python-Guest_Domains-Monitoring-IO_stats.html
* More performance data collected. Flamegraph collected.
  Separated flamegraph for loaded/slow OSD's.
* blktrace
* Historic/Slow requests visualization
* Latency heatmap
* Don't use ftrace if not explicitly allowed, as it may crush a kernel

Estimate caches size:
  * KDE on histo
  * find a numeric extremums
  * calculate histo cum size between minimumss

Collect:
--------
* get node names from hosts
* OSD logging levels
* Aggregate osd by settings
* Better parallelism
* Ceph perf dump
* Logs from down OSD
* Analyze filestore logs to get a typical load profile
* max-sectors-kb linux setting - ????
* dump /sys/block/<dev>/queue
* github.com/cernceph/ceph-scripts
* openstack-in-production.blogspot.com,
  mascetti, disk storage at cern, CHEP 2015
  find flickr paper about ceph
  cds.cern.ch/record/2015206


Report:
-------
* In all reports merge equal lines
* CRUSH visualization:
    - Visualize osd roots separatelly
    - Use pre-calculated graps
    - don't show OSD on graph, only start from hosts
* Violin plots for OSD stage time
* Violin plots for stage time per OSD count


Need to think:
--------------
* Auto-install perf, ceph-devel, smart-tools
* Trace operations using ftrace
