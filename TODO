Проверки:
    * нечетное количество мониторов
    * все оsd имеют классы
    * IOPS per disk/osd

* в таблице для нод отметить IP, отвечающие за ceph сети. К ip дописать имя адаптера
* cpu usage for OSD нужно делить на время жизни
* Tab c ошибками и ворнингами из сеф логов
* для репликации используется нода верхнего уровня
* учесть классы в репликации. фактически классы являются рутами, сделать для них отдельные руты вида default(hdd)
* кривые пулы rgw
* Сделать статистику сетевых карт - переданные пакеты, ошибки, etc
* статистика по подсетям аггрегированная по всем нодам
* для ноды статистика превышений лимитов обработки по всем интерфейсам
* tcp соединения монитора
* таблица соединений между серверами
* uname, uptime сервера
* systemctl -a
* таблица настроек ядра
* вытаскивать ошибки и ворнинги из сеф логов
* CPU/RAM потребление

Загрузка данных:
    performance
    devices
    hosts
    cluster
    ceph

• cache hit ratio
• node total ram for ceph cache
• check bs cache settings for class
• node net with for ceph networks
• node disk types for ceph
• node total ceph storage
• show used space distribution for osd
• group osds into ranges, make a link to ranges
• when press on link - line hightlitten in result table
CPU/RAM потребление
removed snaps - прочитать что это, как его настраивать и чекать, что их не слишком много

Future maybe:
    * всплывающие подсказки. Сделать через js
    * используя pg dump посчитать примерное распределение объектов по размерам??
    * Нарисовать HDD для ноды с разбиением и использованием
    * Вытащить больше инфы из PG/OSD dump - там есть тайминги реквестов на OSD и гистограмма текущей очереди
    * нарисовать краш
